{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7854953,"sourceType":"datasetVersion","datasetId":4607039},{"sourceId":16093,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":13420}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-16T02:31:12.686407Z","iopub.execute_input":"2024-03-16T02:31:12.687223Z","iopub.status.idle":"2024-03-16T02:31:13.051071Z","shell.execute_reply.started":"2024-03-16T02:31:12.687189Z","shell.execute_reply":"2024-03-16T02:31:13.050143Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"/kaggle/input/trained_final/other/v2/1/v_2bert_sentiment_model_final_on_Twitter.bin\n/kaggle/input/fb-data/final_facebookfile.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install bertopic\n!pip install --upgrade nltk","metadata":{"execution":{"iopub.status.busy":"2024-03-16T02:31:13.052821Z","iopub.execute_input":"2024-03-16T02:31:13.053213Z","iopub.status.idle":"2024-03-16T02:32:59.406278Z","shell.execute_reply.started":"2024-03-16T02:31:13.053185Z","shell.execute_reply":"2024-03-16T02:32:59.405067Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Collecting bertopic\n  Downloading bertopic-0.16.0-py2.py3-none-any.whl.metadata (21 kB)\nRequirement already satisfied: numpy>=1.20.0 in /opt/conda/lib/python3.10/site-packages (from bertopic) (1.26.4)\nCollecting hdbscan>=0.8.29 (from bertopic)\n  Downloading hdbscan-0.8.33.tar.gz (5.2 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m56.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: umap-learn>=0.5.0 in /opt/conda/lib/python3.10/site-packages (from bertopic) (0.5.5)\nRequirement already satisfied: pandas>=1.1.5 in /opt/conda/lib/python3.10/site-packages (from bertopic) (2.1.4)\nRequirement already satisfied: scikit-learn>=0.22.2.post1 in /opt/conda/lib/python3.10/site-packages (from bertopic) (1.2.2)\nRequirement already satisfied: tqdm>=4.41.1 in /opt/conda/lib/python3.10/site-packages (from bertopic) (4.66.1)\nCollecting sentence-transformers>=0.4.1 (from bertopic)\n  Downloading sentence_transformers-2.5.1-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: plotly>=4.7.0 in /opt/conda/lib/python3.10/site-packages (from bertopic) (5.18.0)\nCollecting cython<3,>=0.27 (from hdbscan>=0.8.29->bertopic)\n  Using cached Cython-0.29.37-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl.metadata (3.1 kB)\nRequirement already satisfied: scipy>=1.0 in /opt/conda/lib/python3.10/site-packages (from hdbscan>=0.8.29->bertopic) (1.11.4)\nRequirement already satisfied: joblib>=1.0 in /opt/conda/lib/python3.10/site-packages (from hdbscan>=0.8.29->bertopic) (1.3.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.5->bertopic) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.5->bertopic) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.5->bertopic) (2023.4)\nRequirement already satisfied: tenacity>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from plotly>=4.7.0->bertopic) (8.2.3)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from plotly>=4.7.0->bertopic) (21.3)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.22.2.post1->bertopic) (3.2.0)\nRequirement already satisfied: transformers<5.0.0,>=4.32.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers>=0.4.1->bertopic) (4.38.1)\nRequirement already satisfied: torch>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers>=0.4.1->bertopic) (2.1.2)\nRequirement already satisfied: huggingface-hub>=0.15.1 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers>=0.4.1->bertopic) (0.20.3)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from sentence-transformers>=0.4.1->bertopic) (9.5.0)\nRequirement already satisfied: numba>=0.51.2 in /opt/conda/lib/python3.10/site-packages (from umap-learn>=0.5.0->bertopic) (0.58.1)\nRequirement already satisfied: pynndescent>=0.5 in /opt/conda/lib/python3.10/site-packages (from umap-learn>=0.5.0->bertopic) (0.5.11)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic) (3.13.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic) (2024.2.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic) (2.31.0)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic) (6.0.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic) (4.9.0)\nRequirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /opt/conda/lib/python3.10/site-packages (from numba>=0.51.2->umap-learn>=0.5.0->bertopic) (0.41.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->plotly>=4.7.0->bertopic) (3.1.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=1.1.5->bertopic) (1.16.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (3.1.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers>=0.4.1->bertopic) (2023.12.25)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers>=0.4.1->bertopic) (0.15.2)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers>=0.4.1->bertopic) (0.4.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic) (2024.2.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (1.3.0)\nDownloading bertopic-0.16.0-py2.py3-none-any.whl (154 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.1/154.1 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading sentence_transformers-2.5.1-py3-none-any.whl (156 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.5/156.5 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hUsing cached Cython-0.29.37-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (1.9 MB)\nBuilding wheels for collected packages: hdbscan\n  Building wheel for hdbscan (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for hdbscan: filename=hdbscan-0.8.33-cp310-cp310-linux_x86_64.whl size=819466 sha256=7080d7e6629734423b5b9befd81f4c06f08d0a9c31999ae7d483836a297946e6\n  Stored in directory: /root/.cache/pip/wheels/75/0b/3b/dc4f60b7cc455efaefb62883a7483e76f09d06ca81cf87d610\nSuccessfully built hdbscan\nInstalling collected packages: cython, hdbscan, sentence-transformers, bertopic\n  Attempting uninstall: cython\n    Found existing installation: Cython 3.0.8\n    Uninstalling Cython-3.0.8:\n      Successfully uninstalled Cython-3.0.8\nSuccessfully installed bertopic-0.16.0 cython-0.29.37 hdbscan-0.8.33 sentence-transformers-2.5.1\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (3.2.4)\nCollecting nltk\n  Downloading nltk-3.8.1-py3-none-any.whl.metadata (2.8 kB)\nRequirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from nltk) (8.1.7)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from nltk) (1.3.2)\nRequirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.10/site-packages (from nltk) (2023.12.25)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from nltk) (4.66.1)\nDownloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nltk\n  Attempting uninstall: nltk\n    Found existing installation: nltk 3.2.4\n    Uninstalling nltk-3.2.4:\n      Successfully uninstalled nltk-3.2.4\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npreprocessing 0.1.13 requires nltk==3.2.4, but you have nltk 3.8.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed nltk-3.8.1\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\n\ndf = pd.read_csv('/kaggle/input/fb-data/final_facebookfile.csv')  # replace 'your_data.csv' with the path to your file","metadata":{"execution":{"iopub.status.busy":"2024-03-16T03:14:18.842442Z","iopub.execute_input":"2024-03-16T03:14:18.843158Z","iopub.status.idle":"2024-03-16T03:14:18.898544Z","shell.execute_reply.started":"2024-03-16T03:14:18.843122Z","shell.execute_reply":"2024-03-16T03:14:18.897766Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"df['unique_id'] = range(len(df))\n\ndf['Post'] = df['Post'].str.lower()\n","metadata":{"execution":{"iopub.status.busy":"2024-03-16T03:14:24.253177Z","iopub.execute_input":"2024-03-16T03:14:24.253844Z","iopub.status.idle":"2024-03-16T03:14:24.281045Z","shell.execute_reply.started":"2024-03-16T03:14:24.253814Z","shell.execute_reply":"2024-03-16T03:14:24.280013Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"df = df.dropna(subset=['Post'])","metadata":{"execution":{"iopub.status.busy":"2024-03-16T03:14:24.586586Z","iopub.execute_input":"2024-03-16T03:14:24.586883Z","iopub.status.idle":"2024-03-16T03:14:24.595610Z","shell.execute_reply.started":"2024-03-16T03:14:24.586859Z","shell.execute_reply":"2024-03-16T03:14:24.594716Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"execution":{"iopub.status.busy":"2024-03-16T03:14:25.365558Z","iopub.execute_input":"2024-03-16T03:14:25.365916Z","iopub.status.idle":"2024-03-16T03:14:25.371866Z","shell.execute_reply.started":"2024-03-16T03:14:25.365886Z","shell.execute_reply":"2024-03-16T03:14:25.370979Z"},"trusted":true},"execution_count":39,"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"(6596, 5)"},"metadata":{}}]},{"cell_type":"code","source":"df.head(3)","metadata":{"execution":{"iopub.status.busy":"2024-03-16T03:14:26.591521Z","iopub.execute_input":"2024-03-16T03:14:26.592190Z","iopub.status.idle":"2024-03-16T03:14:26.603350Z","shell.execute_reply.started":"2024-03-16T03:14:26.592155Z","shell.execute_reply":"2024-03-16T03:14:26.602299Z"},"trusted":true},"execution_count":40,"outputs":[{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"   Unnamed: 0                                               Post  year  \\\n0           0  hydrogel is the key ingredient which enabled t...  2020   \n1           1  jesus chastised the religious elite of his day...  2020   \n2           2  frances frame is owning her power!\\n.\\ni love ...  2020   \n\n             keyword  unique_id  \n0  health_biosensers          0  \n1  health_biosensers          1  \n2  health_biosensers          2  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>Post</th>\n      <th>year</th>\n      <th>keyword</th>\n      <th>unique_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>hydrogel is the key ingredient which enabled t...</td>\n      <td>2020</td>\n      <td>health_biosensers</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>jesus chastised the religious elite of his day...</td>\n      <td>2020</td>\n      <td>health_biosensers</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>frances frame is owning her power!\\n.\\ni love ...</td>\n      <td>2020</td>\n      <td>health_biosensers</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df_copy = df.copy()","metadata":{"execution":{"iopub.status.busy":"2024-03-16T03:14:28.760774Z","iopub.execute_input":"2024-03-16T03:14:28.761153Z","iopub.status.idle":"2024-03-16T03:14:28.766732Z","shell.execute_reply.started":"2024-03-16T03:14:28.761123Z","shell.execute_reply":"2024-03-16T03:14:28.765656Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics import classification_report\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.svm import SVC\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.metrics import classification_report\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\nimport nltk\nimport re\n\n# Download NLTK resources\nnltk.download('punkt')\nnltk.download('stopwords')\nnltk.download('wordnet')","metadata":{"execution":{"iopub.status.busy":"2024-03-16T03:14:31.343815Z","iopub.execute_input":"2024-03-16T03:14:31.344703Z","iopub.status.idle":"2024-03-16T03:14:31.358133Z","shell.execute_reply.started":"2024-03-16T03:14:31.344670Z","shell.execute_reply":"2024-03-16T03:14:31.357131Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n","output_type":"stream"},{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"import re\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\n\ndef preprocess_text(text):\n    # Check if the text contains only ASCII characters\n    if all(ord(char) < 128 for char in text):\n        # Convert text to lowercase\n        text = text.lower()\n        # Remove URLs\n        text = re.sub(r'http\\S+|www.\\S+', '', text)\n        # Remove special characters, numbers, and punctuations\n        text = ''.join([char for char in text if char.isalnum() or char.isspace()])\n        # Remove specific terms like 'url', 'images', and 'thumbnail'\n        text = re.sub(r'\\b(url|images|thumbnail)\\b', '', text)\n        return text\n    else:\n        return ''  # Return empty string for non-English text\n\n# Tokenization, Stopwords Removal, and Lemmatization\nstop_words = set(stopwords.words('english'))\nlemmatizer = WordNetLemmatizer()\n\ndef tokenize_and_lemmatize(text):\n    # Tokenize the text\n    tokens = word_tokenize(text)\n    # Remove stopwords and lemmatize\n    tokens = [lemmatizer.lemmatize(token) for token in tokens if token.lower() not in stop_words]\n    return ' '.join(tokens)\n\n# Apply preprocessing to the entire dataset\n# Assuming df_copy is defined somewhere in your code\ndf_copy['Post'] = df_copy['Post'].apply(preprocess_text)\ndf_copy['Post'] = df_copy['Post'].apply(tokenize_and_lemmatize)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-16T03:17:03.412232Z","iopub.execute_input":"2024-03-16T03:17:03.413109Z","iopub.status.idle":"2024-03-16T03:17:06.855876Z","shell.execute_reply.started":"2024-03-16T03:17:03.413075Z","shell.execute_reply":"2024-03-16T03:17:06.854717Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"df_copy.shape","metadata":{"execution":{"iopub.status.busy":"2024-03-16T03:17:06.857903Z","iopub.execute_input":"2024-03-16T03:17:06.858302Z","iopub.status.idle":"2024-03-16T03:17:06.864901Z","shell.execute_reply.started":"2024-03-16T03:17:06.858268Z","shell.execute_reply":"2024-03-16T03:17:06.863886Z"},"trusted":true},"execution_count":48,"outputs":[{"execution_count":48,"output_type":"execute_result","data":{"text/plain":"(6596, 5)"},"metadata":{}}]},{"cell_type":"code","source":"# Drop rows with an empty string in the 'Post' column\ndf_copy.dropna(subset=['Post'], inplace=True)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-16T03:19:30.224356Z","iopub.execute_input":"2024-03-16T03:19:30.224777Z","iopub.status.idle":"2024-03-16T03:19:30.233793Z","shell.execute_reply.started":"2024-03-16T03:19:30.224743Z","shell.execute_reply":"2024-03-16T03:19:30.232637Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"df_copy.shape","metadata":{"execution":{"iopub.status.busy":"2024-03-16T03:19:30.742805Z","iopub.execute_input":"2024-03-16T03:19:30.743180Z","iopub.status.idle":"2024-03-16T03:19:30.749517Z","shell.execute_reply.started":"2024-03-16T03:19:30.743152Z","shell.execute_reply":"2024-03-16T03:19:30.748640Z"},"trusted":true},"execution_count":55,"outputs":[{"execution_count":55,"output_type":"execute_result","data":{"text/plain":"(6596, 5)"},"metadata":{}}]},{"cell_type":"code","source":"# Assuming df is your DataFrame with a 'text' column\ndf_copy['Post'] = df_copy['Post'].astype(str)  # Convert to string type to ensure consistency\n\n# Remove duplicates from the 'text' column\ndf_copy.drop_duplicates(subset='Post', inplace=True)\n\n# Now df contains unique values in the 'text' column","metadata":{"execution":{"iopub.status.busy":"2024-03-16T03:19:31.615464Z","iopub.execute_input":"2024-03-16T03:19:31.616204Z","iopub.status.idle":"2024-03-16T03:19:31.625089Z","shell.execute_reply.started":"2024-03-16T03:19:31.616171Z","shell.execute_reply":"2024-03-16T03:19:31.624011Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"df_copy.shape","metadata":{"execution":{"iopub.status.busy":"2024-03-16T03:19:35.934495Z","iopub.execute_input":"2024-03-16T03:19:35.935348Z","iopub.status.idle":"2024-03-16T03:19:35.941205Z","shell.execute_reply.started":"2024-03-16T03:19:35.935317Z","shell.execute_reply":"2024-03-16T03:19:35.940176Z"},"trusted":true},"execution_count":57,"outputs":[{"execution_count":57,"output_type":"execute_result","data":{"text/plain":"(5391, 5)"},"metadata":{}}]},{"cell_type":"code","source":"import torch\nfrom transformers import BertForSequenceClassification, BertTokenizer\n\n# Specify the path where you saved the model and optimizer state\nload_path = \"/kaggle/input/trained_final/other/v2/1/v_2bert_sentiment_model_final_on_Twitter.bin\"\n\n# Initialize the model and optimizer architecture\nmodel = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=3)\noptimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n\n# Load the model and optimizer states\ncheckpoint = torch.load(load_path)\nmodel.load_state_dict(checkpoint['model_state_dict'])\noptimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n\n# Other components\nclass_weights_tensor = checkpoint['class_weights']\ntokenizer = checkpoint['tokenizer']\nmax_length = checkpoint['max_length']\n\n# Move the model to the appropriate device (CPU or GPU)\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-03-16T03:19:41.695066Z","iopub.execute_input":"2024-03-16T03:19:41.695701Z","iopub.status.idle":"2024-03-16T03:19:43.872784Z","shell.execute_reply.started":"2024-03-16T03:19:41.695659Z","shell.execute_reply":"2024-03-16T03:19:43.871832Z"},"trusted":true},"execution_count":58,"outputs":[{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"execution_count":58,"output_type":"execute_result","data":{"text/plain":"BertForSequenceClassification(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (dropout): Dropout(p=0.1, inplace=False)\n  (classifier): Linear(in_features=768, out_features=3, bias=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"import torch\nfrom transformers import BertForSequenceClassification, BertTokenizer\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom bertopic import BERTopic\nimport pandas as pd\n\n# Load the pre-trained BERT model and tokenizer\nload_path = \"/kaggle/input/trained_final/other/v2/1/v_2bert_sentiment_model_final_on_Twitter.bin\"\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\nmodel = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=3)\ncheckpoint = torch.load(load_path, map_location=torch.device('cpu'))\nmodel.load_state_dict(checkpoint['model_state_dict'])\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\n# Read the data\n# df = pd.read_csv(\"D:\\\\Desktop Files\\\\FB_SCRAPES\\\\Reddit\\\\CODED_RAW_coder_validation_reddit_10_percent.csv\")\n\n# Drop unrelated rows and remove null values\n# df_copy = df_copy[~df_copy['Unnamed: 2'].str.contains('unrelated', na=False)]\ndf_copy = df_copy.dropna(subset=['Post'])\n# df_copy = df_copy.drop('Unnamed: 2', axis=1)\n\ndef perform_sentiment_analysis(texts, model, tokenizer, batch_size=4):\n    # Tokenize and convert to tensors\n    predictions = []\n    num_texts = len(texts)\n    for i in range(0, num_texts, batch_size):\n        batch_texts = texts[i:i+batch_size]\n        batch_texts = [str(text) for text in batch_texts]  # Ensure each element is a string\n        tokens = tokenizer(batch_texts, padding=True, truncation=True, return_tensors=\"pt\")\n        inputs = {key: tokens[key].to(device) for key in tokens}\n\n        # Perform inference using the loaded model\n        model.eval()\n        with torch.no_grad():\n            outputs = model(**inputs)\n            _, preds = torch.max(outputs.logits, 1)\n            predictions.extend(preds.cpu().numpy())\n\n    return predictions\n\n\n# Specify batch size\nbatch_size = 2  # Adjust as needed\n\ndf_copy['predicted_sentiment'] = perform_sentiment_analysis(df_copy['Post'], model, tokenizer, batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2024-03-16T03:19:45.985161Z","iopub.execute_input":"2024-03-16T03:19:45.985529Z","iopub.status.idle":"2024-03-16T03:20:26.864413Z","shell.execute_reply.started":"2024-03-16T03:19:45.985499Z","shell.execute_reply":"2024-03-16T03:20:26.863610Z"},"trusted":true},"execution_count":59,"outputs":[{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"df_copy.head(5)","metadata":{"execution":{"iopub.status.busy":"2024-03-16T03:20:26.866268Z","iopub.execute_input":"2024-03-16T03:20:26.866906Z","iopub.status.idle":"2024-03-16T03:20:26.878373Z","shell.execute_reply.started":"2024-03-16T03:20:26.866872Z","shell.execute_reply":"2024-03-16T03:20:26.877377Z"},"trusted":true},"execution_count":60,"outputs":[{"execution_count":60,"output_type":"execute_result","data":{"text/plain":"   Unnamed: 0                                               Post  year  \\\n0           0  hydrogel key ingredient enabled torture human ...  2020   \n1           1  jesus chastised religious elite day able see s...  2020   \n2           2  france frame owning power love friend also cli...  2020   \n3           3  would like share detail achieving vyvo thanks ...  2020   \n4           4  thing amazing seriously im amazed technology i...  2020   \n\n             keyword  unique_id  predicted_sentiment  \n0  health_biosensers          0                    2  \n1  health_biosensers          1                    2  \n2  health_biosensers          2                    2  \n3  health_biosensers          3                    2  \n4  health_biosensers          4                    2  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>Post</th>\n      <th>year</th>\n      <th>keyword</th>\n      <th>unique_id</th>\n      <th>predicted_sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>hydrogel key ingredient enabled torture human ...</td>\n      <td>2020</td>\n      <td>health_biosensers</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>jesus chastised religious elite day able see s...</td>\n      <td>2020</td>\n      <td>health_biosensers</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>france frame owning power love friend also cli...</td>\n      <td>2020</td>\n      <td>health_biosensers</td>\n      <td>2</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>would like share detail achieving vyvo thanks ...</td>\n      <td>2020</td>\n      <td>health_biosensers</td>\n      <td>3</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>thing amazing seriously im amazed technology i...</td>\n      <td>2020</td>\n      <td>health_biosensers</td>\n      <td>4</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df_copy['predicted_sentiment_category'] = df_copy['predicted_sentiment'].map({0: 'negative', 1: 'neutral', 2: 'positive'})","metadata":{"execution":{"iopub.status.busy":"2024-03-16T03:20:26.879541Z","iopub.execute_input":"2024-03-16T03:20:26.879806Z","iopub.status.idle":"2024-03-16T03:20:26.890582Z","shell.execute_reply.started":"2024-03-16T03:20:26.879783Z","shell.execute_reply":"2024-03-16T03:20:26.889789Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"df_copy.shape","metadata":{"execution":{"iopub.status.busy":"2024-03-16T03:20:26.892558Z","iopub.execute_input":"2024-03-16T03:20:26.892863Z","iopub.status.idle":"2024-03-16T03:20:26.908077Z","shell.execute_reply.started":"2024-03-16T03:20:26.892831Z","shell.execute_reply":"2024-03-16T03:20:26.907166Z"},"trusted":true},"execution_count":62,"outputs":[{"execution_count":62,"output_type":"execute_result","data":{"text/plain":"(5391, 7)"},"metadata":{}}]},{"cell_type":"code","source":"import random\n\n# Set a random seed\nrandom.seed(42)  # You can use any integer value here\n\n# Perform topic modeling without sentiment analysis\n# Initialize BERTopic model\ntopic_model = BERTopic(language=\"english\", nr_topics= 10, calculate_probabilities=True, n_gram_range=(1, 1))\n\n# Fit BERTopic model to preprocessed text data\ntexts = df_copy['Post'].tolist()\ntopics, probabilities = topic_model.fit_transform(texts)\n\n# Add main words for each topic as a new column\nmain_words_list = [topic_model.get_topic(topic) for topic in topics]\nwords_only_list = [[word[0] for word in main_words] for main_words in main_words_list]\ndf_copy['main_words_only'] = words_only_list\n\n# Assign topic labels to documents\ndf_copy['topic_label'] = topics\n\n# Determine dominant sentiment for each topic label\ndominant_sentiment_per_topic = {}\nfor topic_id in set(topics):\n    topic_indices = df_copy[df_copy['topic_label'] == topic_id].index\n    topic_sentiments = df_copy.loc[topic_indices, 'predicted_sentiment']\n    sentiment_counts = topic_sentiments.value_counts()\n    if len(sentiment_counts) >= 2:\n        dominant_sentiment = sentiment_counts.index[0]  # Get the most frequent sentiment for the topic\n        second_dominant_sentiment = sentiment_counts.index[1]  # Get the second most frequent sentiment for the topic\n    else:\n        dominant_sentiment = sentiment_counts.index[0]\n        second_dominant_sentiment = None\n    dominant_sentiment_per_topic[topic_id] = (dominant_sentiment, second_dominant_sentiment)\n\n# Map dominant sentiment to each topic label\ndf_copy['dominant_sentiment'], df_copy['second_dominant_sentiment'] = zip(*df_copy['topic_label'].map(dominant_sentiment_per_topic))\n\n# Display the DataFrame\nprint(df_copy)","metadata":{"execution":{"iopub.status.busy":"2024-03-16T03:23:15.574864Z","iopub.execute_input":"2024-03-16T03:23:15.575250Z","iopub.status.idle":"2024-03-16T03:23:32.226384Z","shell.execute_reply.started":"2024-03-16T03:23:15.575221Z","shell.execute_reply":"2024-03-16T03:23:32.225329Z"},"trusted":true},"execution_count":72,"outputs":[{"name":"stdout","text":"      Unnamed: 0                                               Post  year  \\\n0              0  hydrogel key ingredient enabled torture human ...  2020   \n1              1  jesus chastised religious elite day able see s...  2020   \n2              2  france frame owning power love friend also cli...  2020   \n3              3  would like share detail achieving vyvo thanks ...  2020   \n4              4  thing amazing seriously im amazed technology i...  2020   \n...          ...                                                ...   ...   \n6597        6597  biodegradable sensor monitor level pesticide v...  2024   \n6600        6600  much necessary sleep professional athlete slee...  2024   \n6601        6601  movement detective motion tracking physiothera...  2024   \n6602        6602  sg micro operational amplifier sgm8634 low noi...  2024   \n6603        6603  happy international woman day today every day ...  2024   \n\n                keyword  unique_id  predicted_sentiment  \\\n0     health_biosensers          0                    2   \n1     health_biosensers          1                    2   \n2     health_biosensers          2                    2   \n3     health_biosensers          3                    2   \n4     health_biosensers          4                    2   \n...                 ...        ...                  ...   \n6597   wearable_sensors       6587                    2   \n6600   wearable_sensors       6590                    2   \n6601   wearable_sensors       6591                    2   \n6602   wearable_sensors       6592                    0   \n6603   wearable_sensors       6593                    2   \n\n     predicted_sentiment_category  \\\n0                        positive   \n1                        positive   \n2                        positive   \n3                        positive   \n4                        positive   \n...                           ...   \n6597                     positive   \n6600                     positive   \n6601                     positive   \n6602                     negative   \n6603                     positive   \n\n                                        main_words_only  topic_label  \\\n0     [wearable, see, health, sensor, medical, techn...           -1   \n1     [wearable, see, health, sensor, medical, techn...           -1   \n2     [wearable, see, health, sensor, medical, techn...           -1   \n3     [wearable, see, health, sensor, medical, techn...           -1   \n4     [wearable, sensor, see, health, medical, watch...            0   \n...                                                 ...          ...   \n6597  [wearable, see, health, sensor, medical, techn...           -1   \n6600  [wearable, sensor, see, health, medical, watch...            0   \n6601  [wearable, sensor, see, health, medical, watch...            0   \n6602  [wearable, sensor, see, health, medical, watch...            0   \n6603  [wearable, see, health, sensor, medical, techn...           -1   \n\n      dominant_sentiment  second_dominant_sentiment  \\\n0                      2                          1   \n1                      2                          1   \n2                      2                          1   \n3                      2                          1   \n4                      2                          1   \n...                  ...                        ...   \n6597                   2                          1   \n6600                   2                          1   \n6601                   2                          1   \n6602                   2                          1   \n6603                   2                          1   \n\n     dominant_sentiment_category second_dominant_sentiment_category  \n0                       positive                            neutral  \n1                       positive                           negative  \n2                       positive                            neutral  \n3                       positive                            neutral  \n4                       positive                            neutral  \n...                          ...                                ...  \n6597                    positive                            neutral  \n6600                    positive                            neutral  \n6601                    positive                            neutral  \n6602                    positive                            neutral  \n6603                    positive                            neutral  \n\n[5391 rows x 13 columns]\n","output_type":"stream"}]},{"cell_type":"code","source":"# Map predictions to the new column\ndf_copy['dominant_sentiment_category'] = df_copy['dominant_sentiment'].map({0: 'negative', 1: 'neutral', 2: 'positive'})\n\ndf_copy['second_dominant_sentiment_category'] = df_copy['second_dominant_sentiment'].map({0: 'negative', 1: 'neutral', 2: 'positive'})","metadata":{"execution":{"iopub.status.busy":"2024-03-16T03:23:32.228112Z","iopub.execute_input":"2024-03-16T03:23:32.228447Z","iopub.status.idle":"2024-03-16T03:23:32.236062Z","shell.execute_reply.started":"2024-03-16T03:23:32.228420Z","shell.execute_reply":"2024-03-16T03:23:32.234928Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"df_copy.columns","metadata":{"execution":{"iopub.status.busy":"2024-03-16T03:23:32.237277Z","iopub.execute_input":"2024-03-16T03:23:32.237549Z","iopub.status.idle":"2024-03-16T03:23:32.251197Z","shell.execute_reply.started":"2024-03-16T03:23:32.237525Z","shell.execute_reply":"2024-03-16T03:23:32.250199Z"},"trusted":true},"execution_count":74,"outputs":[{"execution_count":74,"output_type":"execute_result","data":{"text/plain":"Index(['Unnamed: 0', 'Post', 'year', 'keyword', 'unique_id',\n       'predicted_sentiment', 'predicted_sentiment_category',\n       'main_words_only', 'topic_label', 'dominant_sentiment',\n       'second_dominant_sentiment', 'dominant_sentiment_category',\n       'second_dominant_sentiment_category'],\n      dtype='object')"},"metadata":{}}]},{"cell_type":"code","source":"# If you want to merge the original and preprocessed DataFrames later\nmerged_df = pd.merge(df, df_copy[['Post', 'year','keyword','unique_id','predicted_sentiment','predicted_sentiment_category','main_words_only','topic_label','dominant_sentiment','second_dominant_sentiment']], on='unique_id', how='inner')\n\n# Now, merged_df contains both 'text_x' and 'text_y' columns\n# You can access them as merged_df['text_x'] and merged_df['text_y']\n\n# Drop the preprocessed text column\n#merged_df.drop('Unnamed: 0', axis=1, inplace=True)\n\n\n\n# Rename the original text column for clarity\nmerged_df.rename(columns={'Post_x': 'original_post'}, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-03-16T03:23:32.253312Z","iopub.execute_input":"2024-03-16T03:23:32.253606Z","iopub.status.idle":"2024-03-16T03:23:32.272007Z","shell.execute_reply.started":"2024-03-16T03:23:32.253581Z","shell.execute_reply":"2024-03-16T03:23:32.271100Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"code","source":"merged_df.head(5)","metadata":{"execution":{"iopub.status.busy":"2024-03-16T03:23:32.273071Z","iopub.execute_input":"2024-03-16T03:23:32.273337Z","iopub.status.idle":"2024-03-16T03:23:32.292342Z","shell.execute_reply.started":"2024-03-16T03:23:32.273307Z","shell.execute_reply":"2024-03-16T03:23:32.291444Z"},"trusted":true},"execution_count":76,"outputs":[{"execution_count":76,"output_type":"execute_result","data":{"text/plain":"   Unnamed: 0                                      original_post  year_x  \\\n0           0  hydrogel is the key ingredient which enabled t...    2020   \n1           1  jesus chastised the religious elite of his day...    2020   \n2           2  frances frame is owning her power!\\n.\\ni love ...    2020   \n3           3  i would like to share with all of you some det...    2020   \n4           4  this thing is amazing! \\nseriously, i’m so ama...    2020   \n\n           keyword_x  unique_id  \\\n0  health_biosensers          0   \n1  health_biosensers          1   \n2  health_biosensers          2   \n3  health_biosensers          3   \n4  health_biosensers          4   \n\n                                              Post_y  year_y  \\\n0  hydrogel key ingredient enabled torture human ...    2020   \n1  jesus chastised religious elite day able see s...    2020   \n2  france frame owning power love friend also cli...    2020   \n3  would like share detail achieving vyvo thanks ...    2020   \n4  thing amazing seriously im amazed technology i...    2020   \n\n           keyword_y  predicted_sentiment predicted_sentiment_category  \\\n0  health_biosensers                    2                     positive   \n1  health_biosensers                    2                     positive   \n2  health_biosensers                    2                     positive   \n3  health_biosensers                    2                     positive   \n4  health_biosensers                    2                     positive   \n\n                                     main_words_only  topic_label  \\\n0  [wearable, see, health, sensor, medical, techn...           -1   \n1  [wearable, see, health, sensor, medical, techn...           -1   \n2  [wearable, see, health, sensor, medical, techn...           -1   \n3  [wearable, see, health, sensor, medical, techn...           -1   \n4  [wearable, sensor, see, health, medical, watch...            0   \n\n   dominant_sentiment  second_dominant_sentiment  \n0                   2                          1  \n1                   2                          1  \n2                   2                          1  \n3                   2                          1  \n4                   2                          1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>original_post</th>\n      <th>year_x</th>\n      <th>keyword_x</th>\n      <th>unique_id</th>\n      <th>Post_y</th>\n      <th>year_y</th>\n      <th>keyword_y</th>\n      <th>predicted_sentiment</th>\n      <th>predicted_sentiment_category</th>\n      <th>main_words_only</th>\n      <th>topic_label</th>\n      <th>dominant_sentiment</th>\n      <th>second_dominant_sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>hydrogel is the key ingredient which enabled t...</td>\n      <td>2020</td>\n      <td>health_biosensers</td>\n      <td>0</td>\n      <td>hydrogel key ingredient enabled torture human ...</td>\n      <td>2020</td>\n      <td>health_biosensers</td>\n      <td>2</td>\n      <td>positive</td>\n      <td>[wearable, see, health, sensor, medical, techn...</td>\n      <td>-1</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>jesus chastised the religious elite of his day...</td>\n      <td>2020</td>\n      <td>health_biosensers</td>\n      <td>1</td>\n      <td>jesus chastised religious elite day able see s...</td>\n      <td>2020</td>\n      <td>health_biosensers</td>\n      <td>2</td>\n      <td>positive</td>\n      <td>[wearable, see, health, sensor, medical, techn...</td>\n      <td>-1</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>frances frame is owning her power!\\n.\\ni love ...</td>\n      <td>2020</td>\n      <td>health_biosensers</td>\n      <td>2</td>\n      <td>france frame owning power love friend also cli...</td>\n      <td>2020</td>\n      <td>health_biosensers</td>\n      <td>2</td>\n      <td>positive</td>\n      <td>[wearable, see, health, sensor, medical, techn...</td>\n      <td>-1</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>i would like to share with all of you some det...</td>\n      <td>2020</td>\n      <td>health_biosensers</td>\n      <td>3</td>\n      <td>would like share detail achieving vyvo thanks ...</td>\n      <td>2020</td>\n      <td>health_biosensers</td>\n      <td>2</td>\n      <td>positive</td>\n      <td>[wearable, see, health, sensor, medical, techn...</td>\n      <td>-1</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>this thing is amazing! \\nseriously, i’m so ama...</td>\n      <td>2020</td>\n      <td>health_biosensers</td>\n      <td>4</td>\n      <td>thing amazing seriously im amazed technology i...</td>\n      <td>2020</td>\n      <td>health_biosensers</td>\n      <td>2</td>\n      <td>positive</td>\n      <td>[wearable, sensor, see, health, medical, watch...</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Save the DataFrame to a CSV file\nmerged_df.to_csv('/kaggle/working/Facebook_BERT_FINAL.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-03-16T03:23:32.293423Z","iopub.execute_input":"2024-03-16T03:23:32.293705Z","iopub.status.idle":"2024-03-16T03:23:32.496035Z","shell.execute_reply.started":"2024-03-16T03:23:32.293681Z","shell.execute_reply":"2024-03-16T03:23:32.494998Z"},"trusted":true},"execution_count":77,"outputs":[]},{"cell_type":"code","source":"# Assuming df_copy contains your DataFrame\nprocessed_texts = df_copy['Post'].tolist()","metadata":{"execution":{"iopub.status.busy":"2024-03-16T03:23:32.497228Z","iopub.execute_input":"2024-03-16T03:23:32.497567Z","iopub.status.idle":"2024-03-16T03:23:32.502229Z","shell.execute_reply.started":"2024-03-16T03:23:32.497540Z","shell.execute_reply":"2024-03-16T03:23:32.501246Z"},"trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"code","source":"topic_model.visualize_barchart()","metadata":{"execution":{"iopub.status.busy":"2024-03-16T03:23:32.503447Z","iopub.execute_input":"2024-03-16T03:23:32.503772Z","iopub.status.idle":"2024-03-16T03:23:32.606599Z","shell.execute_reply.started":"2024-03-16T03:23:32.503741Z","shell.execute_reply":"2024-03-16T03:23:32.605739Z"},"trusted":true},"execution_count":79,"outputs":[{"output_type":"display_data","data":{"text/html":"<div>                            <div id=\"a8863c61-72ea-4d34-ab62-081ed6c9d119\" class=\"plotly-graph-div\" style=\"height:500px; width:1000px;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"a8863c61-72ea-4d34-ab62-081ed6c9d119\")) {                    Plotly.newPlot(                        \"a8863c61-72ea-4d34-ab62-081ed6c9d119\",                        [{\"marker\":{\"color\":\"#D55E00\"},\"orientation\":\"h\",\"x\":[0.022311684464069025,0.03313137164846891,0.03558852913914465,0.037761776510220564,0.04171012468493975],\"y\":[\"medical  \",\"health  \",\"see  \",\"sensor  \",\"wearable  \"],\"type\":\"bar\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"marker\":{\"color\":\"#0072B2\"},\"orientation\":\"h\",\"x\":[0.02624629427658104,0.03688613468840359,0.04051376093278227,0.043576694579090344,0.05261684488782029],\"y\":[\"2022  \",\"mobile  \",\"india  \",\"expo  \",\"see  \"],\"type\":\"bar\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"marker\":{\"color\":\"#CC79A7\"},\"orientation\":\"h\",\"x\":[0.026728407491491413,0.033393172805222776,0.042860411764181934,0.043560485941202515,0.045902476657938354],\"y\":[\"year  \",\"medical  \",\"scrub  \",\"wear  \",\"see  \"],\"type\":\"bar\",\"xaxis\":\"x3\",\"yaxis\":\"y3\"},{\"marker\":{\"color\":\"#E69F00\"},\"orientation\":\"h\",\"x\":[0.13937590013655635,0.14050503951704404,0.19086026964405103,0.23789726666045716,0.24539177525663705],\"y\":[\"128gb  \",\"working  \",\"100  \",\"battery  \",\"iphone  \"],\"type\":\"bar\",\"xaxis\":\"x4\",\"yaxis\":\"y4\"},{\"marker\":{\"color\":\"#56B4E9\"},\"orientation\":\"h\",\"x\":[0.0434238225610843,0.04618687052413328,0.0506391648181308,0.05596920095746724,0.0800725081004179],\"y\":[\"targeted  \",\"mrna  \",\"see  \",\"bio  \",\"vaccine  \"],\"type\":\"bar\",\"xaxis\":\"x5\",\"yaxis\":\"y5\"},{\"marker\":{\"color\":\"#009E73\"},\"orientation\":\"h\",\"x\":[0.321617692823235,0.321617692823235,0.321617692823235,0.41443182120560285,0.5001258132283659],\"y\":[\"craziness  \",\"uooots  \",\"woooow  \",\"interesting  \",\"good  \"],\"type\":\"bar\",\"xaxis\":\"x6\",\"yaxis\":\"y6\"},{\"marker\":{\"color\":\"#F0E442\"},\"orientation\":\"h\",\"x\":[0.17824538427310416,0.18857025275765982,0.2119471419267739,0.24382690922223263,0.3645362170999759],\"y\":[\"including  \",\"shapewear  \",\"binder  \",\"game  \",\"sims  \"],\"type\":\"bar\",\"xaxis\":\"x7\",\"yaxis\":\"y7\"},{\"marker\":{\"color\":\"#D55E00\"},\"orientation\":\"h\",\"x\":[0.15057949118321018,0.16006300746718702,0.16006300746718702,0.1822320240085521,0.26260274553932356],\"y\":[\"issued  \",\"recalling  \",\"sergeant  \",\"duty  \",\"claus  \"],\"type\":\"bar\",\"xaxis\":\"x8\",\"yaxis\":\"y8\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,0.175],\"showgrid\":true},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.6000000000000001,1.0],\"showgrid\":true},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.275,0.45],\"showgrid\":true},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.6000000000000001,1.0],\"showgrid\":true},\"xaxis3\":{\"anchor\":\"y3\",\"domain\":[0.55,0.7250000000000001],\"showgrid\":true},\"yaxis3\":{\"anchor\":\"x3\",\"domain\":[0.6000000000000001,1.0],\"showgrid\":true},\"xaxis4\":{\"anchor\":\"y4\",\"domain\":[0.825,1.0],\"showgrid\":true},\"yaxis4\":{\"anchor\":\"x4\",\"domain\":[0.6000000000000001,1.0],\"showgrid\":true},\"xaxis5\":{\"anchor\":\"y5\",\"domain\":[0.0,0.175],\"showgrid\":true},\"yaxis5\":{\"anchor\":\"x5\",\"domain\":[0.0,0.4],\"showgrid\":true},\"xaxis6\":{\"anchor\":\"y6\",\"domain\":[0.275,0.45],\"showgrid\":true},\"yaxis6\":{\"anchor\":\"x6\",\"domain\":[0.0,0.4],\"showgrid\":true},\"xaxis7\":{\"anchor\":\"y7\",\"domain\":[0.55,0.7250000000000001],\"showgrid\":true},\"yaxis7\":{\"anchor\":\"x7\",\"domain\":[0.0,0.4],\"showgrid\":true},\"xaxis8\":{\"anchor\":\"y8\",\"domain\":[0.825,1.0],\"showgrid\":true},\"yaxis8\":{\"anchor\":\"x8\",\"domain\":[0.0,0.4],\"showgrid\":true},\"annotations\":[{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Topic 0\",\"x\":0.0875,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Topic 1\",\"x\":0.36250000000000004,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Topic 2\",\"x\":0.6375000000000001,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Topic 3\",\"x\":0.9125,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Topic 4\",\"x\":0.0875,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.4,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Topic 5\",\"x\":0.36250000000000004,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.4,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Topic 6\",\"x\":0.6375000000000001,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.4,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Topic 7\",\"x\":0.9125,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.4,\"yanchor\":\"bottom\",\"yref\":\"paper\"}],\"title\":{\"font\":{\"size\":22,\"color\":\"Black\"},\"text\":\"Topic Word Scores\",\"x\":0.5,\"xanchor\":\"center\",\"yanchor\":\"top\"},\"hoverlabel\":{\"font\":{\"size\":16,\"family\":\"Rockwell\"},\"bgcolor\":\"white\"},\"showlegend\":false,\"width\":1000,\"height\":500},                        {\"responsive\": true}                    ).then(function(){\n                            \nvar gd = document.getElementById('a8863c61-72ea-4d34-ab62-081ed6c9d119');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })                };                });            </script>        </div>"},"metadata":{}}]},{"cell_type":"code","source":"topic_model.get_topics()","metadata":{"execution":{"iopub.status.busy":"2024-03-16T03:23:32.607633Z","iopub.execute_input":"2024-03-16T03:23:32.607919Z","iopub.status.idle":"2024-03-16T03:23:32.618847Z","shell.execute_reply.started":"2024-03-16T03:23:32.607889Z","shell.execute_reply":"2024-03-16T03:23:32.617997Z"},"trusted":true},"execution_count":80,"outputs":[{"execution_count":80,"output_type":"execute_result","data":{"text/plain":"{-1: [('wearable', 0.04126008330606888),\n  ('see', 0.036576994787935566),\n  ('health', 0.033138721149882824),\n  ('sensor', 0.031247635601807607),\n  ('medical', 0.02399490029464223),\n  ('technology', 0.021258363610262853),\n  ('device', 0.018961899828157786),\n  ('new', 0.016381204412835672),\n  ('data', 0.015796785585338917),\n  ('healthcare', 0.015069303676012382)],\n 0: [('wearable', 0.04171012468493975),\n  ('sensor', 0.037761776510220564),\n  ('see', 0.03558852913914465),\n  ('health', 0.03313137164846891),\n  ('medical', 0.022311684464069025),\n  ('watch', 0.02091047473359119),\n  ('device', 0.02054230570448239),\n  ('technology', 0.019145505493198878),\n  ('smart', 0.017483920170446855),\n  ('new', 0.016847429646386698)],\n 1: [('see', 0.05261684488782029),\n  ('expo', 0.043576694579090344),\n  ('india', 0.04051376093278227),\n  ('mobile', 0.03688613468840359),\n  ('2022', 0.02624629427658104),\n  ('dti', 0.02557169281393571),\n  ('hiraya', 0.02441232705188244),\n  ('regional', 0.02172474427901237),\n  ('de', 0.020862368058029775),\n  ('trade', 0.01981973192956439)],\n 2: [('see', 0.045902476657938354),\n  ('wear', 0.043560485941202515),\n  ('scrub', 0.042860411764181934),\n  ('medical', 0.033393172805222776),\n  ('year', 0.026728407491491413),\n  ('die', 0.024158358747753253),\n  ('dont', 0.023319264628090572),\n  ('zero', 0.021592061478705314),\n  ('book', 0.02077996334289259),\n  ('season', 0.0206012047261923)],\n 3: [('iphone', 0.24539177525663705),\n  ('battery', 0.23789726666045716),\n  ('100', 0.19086026964405103),\n  ('working', 0.14050503951704404),\n  ('128gb', 0.13937590013655635),\n  ('original', 0.13671358258132058),\n  ('see', 0.1201004991345261),\n  ('health', 0.12002264743242624),\n  ('condition', 0.11130167882623856),\n  ('gb', 0.1030034620108344)],\n 4: [('vaccine', 0.0800725081004179),\n  ('bio', 0.05596920095746724),\n  ('see', 0.0506391648181308),\n  ('mrna', 0.04618687052413328),\n  ('targeted', 0.0434238225610843),\n  ('weapon', 0.03728776729052188),\n  ('individual', 0.03694278122751959),\n  ('human', 0.032673696423625755),\n  ('nanotechnology', 0.030863017773839166),\n  ('trust', 0.02960360133571216)],\n 5: [('good', 0.5001258132283659),\n  ('interesting', 0.41443182120560285),\n  ('woooow', 0.321617692823235),\n  ('uooots', 0.321617692823235),\n  ('craziness', 0.321617692823235),\n  ('dam', 0.29851493741157975),\n  ('saying', 0.2619031288300831),\n  ('fascinating', 0.2523180261033023),\n  ('exactly', 0.248394074550931),\n  ('pushing', 0.248394074550931)],\n 6: [('sims', 0.3645362170999759),\n  ('game', 0.24382690922223263),\n  ('binder', 0.2119471419267739),\n  ('shapewear', 0.18857025275765982),\n  ('including', 0.17824538427310416),\n  ('update', 0.17340166603003487),\n  ('scar', 0.15714187729804985),\n  ('gameplay', 0.13219887945154504),\n  ('added', 0.13210595841896403),\n  ('hearing', 0.13210595841896403)],\n 7: [('claus', 0.26260274553932356),\n  ('duty', 0.1822320240085521),\n  ('sergeant', 0.16006300746718702),\n  ('recalling', 0.16006300746718702),\n  ('issued', 0.15057949118321018),\n  ('rnltd', 0.14452583834079366),\n  ('active', 0.12493954401958846),\n  ('24', 0.12132448765245539),\n  ('order', 0.12004900668146437),\n  ('marine', 0.1125120839842839)],\n 8: [('necklace', 0.2203957861739032),\n  ('lamp', 0.16078701840264523),\n  ('see', 0.14547172957669474),\n  ('faye', 0.08955448122347394),\n  ('housed', 0.08955448122347394),\n  ('neopixel', 0.08955448122347394),\n  ('dew', 0.08955448122347394),\n  ('dovetail', 0.08955448122347394),\n  ('glowables', 0.08955448122347394),\n  ('cinch', 0.08955448122347394)]}"},"metadata":{}}]},{"cell_type":"code","source":"topic_model.visualize_distribution(topic_model.probabilities_[0])","metadata":{"execution":{"iopub.status.busy":"2024-03-16T03:23:41.012922Z","iopub.execute_input":"2024-03-16T03:23:41.013632Z","iopub.status.idle":"2024-03-16T03:23:41.063792Z","shell.execute_reply.started":"2024-03-16T03:23:41.013600Z","shell.execute_reply":"2024-03-16T03:23:41.062745Z"},"trusted":true},"execution_count":81,"outputs":[{"output_type":"display_data","data":{"text/html":"<div>                            <div id=\"c7fa09a7-cf20-4e1c-96f5-264cf159442c\" class=\"plotly-graph-div\" style=\"height:600px; width:800px;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"c7fa09a7-cf20-4e1c-96f5-264cf159442c\")) {                    Plotly.newPlot(                        \"c7fa09a7-cf20-4e1c-96f5-264cf159442c\",                        [{\"marker\":{\"color\":\"#C8D2D7\",\"line\":{\"color\":\"#6E8484\",\"width\":1}},\"orientation\":\"h\",\"x\":[0.7588856396786617,0.030019682254438445,0.026848876878687426,0.03307463128903199],\"y\":[\"\\u003cb\\u003eTopic 0\\u003c\\u002fb\\u003e: wearable_sensor_see_heal...\",\"\\u003cb\\u003eTopic 1\\u003c\\u002fb\\u003e: see_expo_india_mobile_20...\",\"\\u003cb\\u003eTopic 2\\u003c\\u002fb\\u003e: see_wear_scrub_medical_y...\",\"\\u003cb\\u003eTopic 4\\u003c\\u002fb\\u003e: vaccine_bio_see_mrna_tar...\"],\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"rgb(36,36,36)\"},\"error_y\":{\"color\":\"rgb(36,36,36)\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"rgb(36,36,36)\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"rgb(36,36,36)\"},\"baxis\":{\"endlinecolor\":\"rgb(36,36,36)\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"rgb(36,36,36)\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.6}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"rgb(237,237,237)\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"rgb(217,217,217)\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"colorscale\":{\"diverging\":[[0.0,\"rgb(103,0,31)\"],[0.1,\"rgb(178,24,43)\"],[0.2,\"rgb(214,96,77)\"],[0.3,\"rgb(244,165,130)\"],[0.4,\"rgb(253,219,199)\"],[0.5,\"rgb(247,247,247)\"],[0.6,\"rgb(209,229,240)\"],[0.7,\"rgb(146,197,222)\"],[0.8,\"rgb(67,147,195)\"],[0.9,\"rgb(33,102,172)\"],[1.0,\"rgb(5,48,97)\"]],\"sequential\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"sequentialminus\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]]},\"colorway\":[\"#1F77B4\",\"#FF7F0E\",\"#2CA02C\",\"#D62728\",\"#9467BD\",\"#8C564B\",\"#E377C2\",\"#7F7F7F\",\"#BCBD22\",\"#17BECF\"],\"font\":{\"color\":\"rgb(36,36,36)\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"rgb(232,232,232)\",\"gridwidth\":2,\"linecolor\":\"rgb(36,36,36)\",\"showbackground\":true,\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\",\"zeroline\":false,\"zerolinecolor\":\"rgb(36,36,36)\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"rgb(232,232,232)\",\"gridwidth\":2,\"linecolor\":\"rgb(36,36,36)\",\"showbackground\":true,\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\",\"zeroline\":false,\"zerolinecolor\":\"rgb(36,36,36)\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"rgb(232,232,232)\",\"gridwidth\":2,\"linecolor\":\"rgb(36,36,36)\",\"showbackground\":true,\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\",\"zeroline\":false,\"zerolinecolor\":\"rgb(36,36,36)\"}},\"shapedefaults\":{\"fillcolor\":\"black\",\"line\":{\"width\":0},\"opacity\":0.3},\"ternary\":{\"aaxis\":{\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\"},\"baxis\":{\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\",\"title\":{\"standoff\":15},\"zeroline\":false,\"zerolinecolor\":\"rgb(36,36,36)\"},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\",\"title\":{\"standoff\":15},\"zeroline\":false,\"zerolinecolor\":\"rgb(36,36,36)\"}}},\"title\":{\"font\":{\"size\":22,\"color\":\"Black\"},\"text\":\"\\u003cb\\u003eTopic Probability Distribution\\u003c\\u002fb\\u003e\",\"y\":0.95,\"x\":0.5,\"xanchor\":\"center\",\"yanchor\":\"top\"},\"hoverlabel\":{\"font\":{\"size\":16,\"family\":\"Rockwell\"},\"bgcolor\":\"white\"},\"xaxis\":{\"title\":{\"text\":\"Probability\"}},\"width\":800,\"height\":600},                        {\"responsive\": true}                    ).then(function(){\n                            \nvar gd = document.getElementById('c7fa09a7-cf20-4e1c-96f5-264cf159442c');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })                };                });            </script>        </div>"},"metadata":{}}]},{"cell_type":"code","source":"topic_model.visualize_topics()","metadata":{"execution":{"iopub.status.busy":"2024-03-16T03:23:43.353129Z","iopub.execute_input":"2024-03-16T03:23:43.353822Z","iopub.status.idle":"2024-03-16T03:23:44.292056Z","shell.execute_reply.started":"2024-03-16T03:23:43.353791Z","shell.execute_reply":"2024-03-16T03:23:44.291135Z"},"trusted":true},"execution_count":82,"outputs":[{"output_type":"display_data","data":{"text/html":"<div>                            <div id=\"fed1c467-817b-4f23-bf03-6c9426e65064\" class=\"plotly-graph-div\" style=\"height:650px; width:650px;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"fed1c467-817b-4f23-bf03-6c9426e65064\")) {                    Plotly.newPlot(                        \"fed1c467-817b-4f23-bf03-6c9426e65064\",                        [{\"customdata\":[[0,\"wearable | sensor | see | health | medical\",2452],[1,\"see | expo | india | mobile | 2022\",163],[2,\"see | wear | scrub | medical | year\",111],[3,\"iphone | battery | 100 | working | 128gb\",72],[4,\"vaccine | bio | see | mrna | targeted\",69],[5,\"good | interesting | woooow | uooots | craziness\",17],[6,\"sims | game | binder | shapewear | including\",15],[7,\"claus | duty | sergeant | recalling | issued\",13],[8,\"necklace | lamp | see | faye | housed\",12]],\"hovertemplate\":\"\\u003cb\\u003eTopic %{customdata[0]}\\u003c\\u002fb\\u003e\\u003cbr\\u003e%{customdata[1]}\\u003cbr\\u003eSize: %{customdata[2]}\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#B0BEC5\",\"size\":[2452,163,111,72,69,17,15,13,12],\"sizemode\":\"area\",\"sizeref\":1.5325,\"symbol\":\"circle\",\"line\":{\"color\":\"DarkSlateGrey\",\"width\":2}},\"mode\":\"markers\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"x\":[2.435414,1.0920466,1.5236727,2.3100371,2.985503,0.8794045,2.649147,1.5633122,0.70136905],\"xaxis\":\"x\",\"y\":[3.6630762,3.593484,3.4499128,4.2403393,4.003664,4.3551235,3.2750843,2.84255,2.9843864],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"rgb(36,36,36)\"},\"error_y\":{\"color\":\"rgb(36,36,36)\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"rgb(36,36,36)\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"rgb(36,36,36)\"},\"baxis\":{\"endlinecolor\":\"rgb(36,36,36)\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"rgb(36,36,36)\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.6}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"rgb(237,237,237)\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"rgb(217,217,217)\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"colorscale\":{\"diverging\":[[0.0,\"rgb(103,0,31)\"],[0.1,\"rgb(178,24,43)\"],[0.2,\"rgb(214,96,77)\"],[0.3,\"rgb(244,165,130)\"],[0.4,\"rgb(253,219,199)\"],[0.5,\"rgb(247,247,247)\"],[0.6,\"rgb(209,229,240)\"],[0.7,\"rgb(146,197,222)\"],[0.8,\"rgb(67,147,195)\"],[0.9,\"rgb(33,102,172)\"],[1.0,\"rgb(5,48,97)\"]],\"sequential\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"sequentialminus\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]]},\"colorway\":[\"#1F77B4\",\"#FF7F0E\",\"#2CA02C\",\"#D62728\",\"#9467BD\",\"#8C564B\",\"#E377C2\",\"#7F7F7F\",\"#BCBD22\",\"#17BECF\"],\"font\":{\"color\":\"rgb(36,36,36)\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"rgb(232,232,232)\",\"gridwidth\":2,\"linecolor\":\"rgb(36,36,36)\",\"showbackground\":true,\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\",\"zeroline\":false,\"zerolinecolor\":\"rgb(36,36,36)\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"rgb(232,232,232)\",\"gridwidth\":2,\"linecolor\":\"rgb(36,36,36)\",\"showbackground\":true,\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\",\"zeroline\":false,\"zerolinecolor\":\"rgb(36,36,36)\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"rgb(232,232,232)\",\"gridwidth\":2,\"linecolor\":\"rgb(36,36,36)\",\"showbackground\":true,\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\",\"zeroline\":false,\"zerolinecolor\":\"rgb(36,36,36)\"}},\"shapedefaults\":{\"fillcolor\":\"black\",\"line\":{\"width\":0},\"opacity\":0.3},\"ternary\":{\"aaxis\":{\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\"},\"baxis\":{\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\",\"title\":{\"standoff\":15},\"zeroline\":false,\"zerolinecolor\":\"rgb(36,36,36)\"},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\",\"title\":{\"standoff\":15},\"zeroline\":false,\"zerolinecolor\":\"rgb(36,36,36)\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"\"},\"visible\":false,\"range\":[0.5961636900901794,3.433328402042389]},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"\"},\"visible\":false,\"range\":[2.4161675333976746,5.00839204788208]},\"legend\":{\"tracegroupgap\":0,\"itemsizing\":\"constant\"},\"margin\":{\"t\":60},\"title\":{\"font\":{\"size\":22,\"color\":\"Black\"},\"text\":\"\\u003cb\\u003eIntertopic Distance Map\\u003c\\u002fb\\u003e\",\"y\":0.95,\"x\":0.5,\"xanchor\":\"center\",\"yanchor\":\"top\"},\"hoverlabel\":{\"font\":{\"size\":16,\"family\":\"Rockwell\"},\"bgcolor\":\"white\"},\"width\":650,\"height\":650,\"sliders\":[{\"active\":0,\"pad\":{\"t\":50},\"steps\":[{\"args\":[{\"marker.color\":[[\"red\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\"]]}],\"label\":\"Topic 0\",\"method\":\"update\"},{\"args\":[{\"marker.color\":[[\"#B0BEC5\",\"red\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\"]]}],\"label\":\"Topic 1\",\"method\":\"update\"},{\"args\":[{\"marker.color\":[[\"#B0BEC5\",\"#B0BEC5\",\"red\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\"]]}],\"label\":\"Topic 2\",\"method\":\"update\"},{\"args\":[{\"marker.color\":[[\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"red\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\"]]}],\"label\":\"Topic 3\",\"method\":\"update\"},{\"args\":[{\"marker.color\":[[\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"red\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\"]]}],\"label\":\"Topic 4\",\"method\":\"update\"},{\"args\":[{\"marker.color\":[[\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"red\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\"]]}],\"label\":\"Topic 5\",\"method\":\"update\"},{\"args\":[{\"marker.color\":[[\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"red\",\"#B0BEC5\",\"#B0BEC5\"]]}],\"label\":\"Topic 6\",\"method\":\"update\"},{\"args\":[{\"marker.color\":[[\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"red\",\"#B0BEC5\"]]}],\"label\":\"Topic 7\",\"method\":\"update\"},{\"args\":[{\"marker.color\":[[\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"red\"]]}],\"label\":\"Topic 8\",\"method\":\"update\"}]}],\"shapes\":[{\"line\":{\"color\":\"#CFD8DC\",\"width\":2},\"type\":\"line\",\"x0\":2.0147460460662843,\"x1\":2.0147460460662843,\"y0\":2.4161675333976746,\"y1\":5.00839204788208},{\"line\":{\"color\":\"#9E9E9E\",\"width\":2},\"type\":\"line\",\"x0\":0.5961636900901794,\"x1\":3.433328402042389,\"y0\":3.7122797906398777,\"y1\":3.7122797906398777}],\"annotations\":[{\"showarrow\":false,\"text\":\"D1\",\"x\":0.5961636900901794,\"y\":3.7122797906398777,\"yshift\":10},{\"showarrow\":false,\"text\":\"D2\",\"x\":2.0147460460662843,\"xshift\":10,\"y\":5.00839204788208}]},                        {\"responsive\": true}                    ).then(function(){\n                            \nvar gd = document.getElementById('fed1c467-817b-4f23-bf03-6c9426e65064');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })                };                });            </script>        </div>"},"metadata":{}}]},{"cell_type":"code","source":"merged_df.shape","metadata":{"execution":{"iopub.status.busy":"2024-03-16T03:17:56.678581Z","iopub.execute_input":"2024-03-16T03:17:56.679536Z","iopub.status.idle":"2024-03-16T03:17:56.686230Z","shell.execute_reply.started":"2024-03-16T03:17:56.679490Z","shell.execute_reply":"2024-03-16T03:17:56.685196Z"},"trusted":true},"execution_count":51,"outputs":[{"execution_count":51,"output_type":"execute_result","data":{"text/plain":"(5946, 14)"},"metadata":{}}]},{"cell_type":"code","source":"from gensim import corpora\n\n# Assuming processed_texts is a list of strings\n# Split each string into tokens\nprocessed_texts_tokenized = [text.split() for text in processed_texts]\n\n# Create dictionary\ndictionary = corpora.Dictionary(processed_texts_tokenized)\n\n# Create corpus\ncorpus = [dictionary.doc2bow(text) for text in processed_texts_tokenized]\n","metadata":{"execution":{"iopub.status.busy":"2024-03-16T02:35:29.332014Z","iopub.execute_input":"2024-03-16T02:35:29.332705Z","iopub.status.idle":"2024-03-16T02:35:58.822376Z","shell.execute_reply.started":"2024-03-16T02:35:29.332672Z","shell.execute_reply":"2024-03-16T02:35:58.821527Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"import gensim\nfrom gensim.models import LdaModel\nfrom gensim.models.coherencemodel import CoherenceModel# List to store coherence scores\n\ncoherence_scores = []\n\n# Iterate over different numbers of topics\nfor num_topics in range(2, 20):  # Adjust the range as needed\n    # Train LDA model\n    lda_model = gensim.models.LdaModel(corpus, num_topics=num_topics, id2word=dictionary, passes=15)\n    \n    # Compute coherence score\n    coherence_model_lda = CoherenceModel(model=lda_model, texts=processed_texts, dictionary=dictionary, coherence='c_v')\n    coherence_score = coherence_model_lda.get_coherence()\n    coherence_scores.append((num_topics, coherence_score))\n\n# Find the number of topics with the highest coherence score\nbest_num_topics, best_coherence_score = max(coherence_scores, key=lambda x: x[1])\n\nprint(\"Best number of topics:\", best_num_topics)\nprint(\"Coherence score:\", best_coherence_score)","metadata":{"execution":{"iopub.status.busy":"2024-03-16T02:42:04.645218Z","iopub.execute_input":"2024-03-16T02:42:04.645641Z","iopub.status.idle":"2024-03-16T02:58:21.302711Z","shell.execute_reply.started":"2024-03-16T02:42:04.645609Z","shell.execute_reply":"2024-03-16T02:58:21.301547Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n/opt/conda/lib/python3.10/site-packages/gensim/topic_coherence/direct_confirmation_measure.py:204: RuntimeWarning: divide by zero encountered in scalar divide\n  m_lr_i = np.log(numerator / denominator)\n/opt/conda/lib/python3.10/site-packages/gensim/topic_coherence/indirect_confirmation_measure.py:323: RuntimeWarning: invalid value encountered in scalar divide\n  return cv1.T.dot(cv2)[0, 0] / (_magnitude(cv1) * _magnitude(cv2))\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Best number of topics: 2\nCoherence score: nan\n","output_type":"stream"}]},{"cell_type":"code","source":"# Save the DataFrame to a CSV file\nmerged_df.to_csv('/kaggle/working/Facebook_BERT_FINAL.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-03-16T02:58:28.066458Z","iopub.execute_input":"2024-03-16T02:58:28.066758Z","iopub.status.idle":"2024-03-16T02:58:28.295391Z","shell.execute_reply.started":"2024-03-16T02:58:28.066732Z","shell.execute_reply":"2024-03-16T02:58:28.294326Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}